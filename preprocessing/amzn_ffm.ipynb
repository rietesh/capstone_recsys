{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b8bdf5",
   "metadata": {},
   "source": [
    "# Prepare dataset for xDeepFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb76f93",
   "metadata": {},
   "source": [
    "<b>xDeepFM</b> uses the Field-aware Factorization Machine (FFM) format as data input where each row in the dataset has the following: `<label> <field_index_id>:<feature_index_id>:<feature_value>`  \n",
    "Each line represents an instance, `<label>` is a rating value followed by numerical features (userID, itemID)  and categorical features in the FFM format.<br>\n",
    "\n",
    "Features are divided into fields. For example, user's gender is a field, it contains three possible values, i.e. male, female and unknown. Occupation can be another field, which contains many more possible values than the gender field. <b>Both field index and feature index are starting from 1</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c4fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358b022d",
   "metadata": {},
   "source": [
    "## Read the reviews dataset (same one as used by wide_n_deep model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667b4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from recommenders.utils.constants import (\n",
    "    DEFAULT_USER_COL as USER_COL,\n",
    "    DEFAULT_ITEM_COL as ITEM_COL,\n",
    "    DEFAULT_RATING_COL as RATING_COL,\n",
    "    DEFAULT_GENRE_COL as ITEM_FEAT_COL,\n",
    ")\n",
    "\n",
    "DATA_DIR = '/home/shiv/Documents/DataScience/Capstone/Data/'\n",
    "\n",
    "data = pd.read_csv(DATA_DIR + 'wide_deep/Electronics/wide_deep_amzn_e_20.csv', header=None, low_memory=False)\n",
    "data.columns = [USER_COL,ITEM_COL,RATING_COL,ITEM_FEAT_COL,\n",
    "                'unixTimeStamp','title','price','main_cat','category']\n",
    "\n",
    "# data = data[[USER_COL,ITEM_COL,RATING_COL,ITEM_FEAT_COL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21aa6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.sample(frac=1., random_state=42)\n",
    "data.sort_values('unixTimeStamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d8b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2363b7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5613183, 9),\n",
       "    userID  itemID  rating                                              genre  \\\n",
       " 0   81212    5424     5.0  Car Electronics|Electronics|Portable Audio & V...   \n",
       " 1  277508    5407     5.0  All Electronics|Electronics|Computers & Access...   \n",
       " 2  281405    5462     4.0  All Electronics|Electronics|Computers & Access...   \n",
       " 3  277481    5404     4.0  Home Audio & Theater|Electronics|Portable Audi...   \n",
       " 4  215430    5463     3.0  All Electronics|Electronics|Computers & Access...   \n",
       " \n",
       "    unixTimeStamp                                              title   price  \\\n",
       " 0      947462400  Motorola 53725 SLK Headset with Swivel Boom Mi...     $$$   \n",
       " 1      958262400           Belkin CAT5e 3-Feet Cat 5E Network Cable   $5.07   \n",
       " 2      959299200  Cisco-Linksys BEFSR41 EtherFast Cable/DSL Rout...   $2.46   \n",
       " 3      959299200  GE 72887 Superadio III Portable AM/FM Radio (D...     $$$   \n",
       " 4      961200000  D-Link DFE-530TX+ 10/100 Fast Ethernet Desktop...  $12.99   \n",
       " \n",
       "                main_cat                                           category  \n",
       " 0       Car Electronics  Electronics|Portable Audio & Video|CB & Two-Wa...  \n",
       " 1       All Electronics  Electronics|Computers & Accessories|Computer A...  \n",
       " 2       All Electronics  Electronics|Computers & Accessories|Networking...  \n",
       " 3  Home Audio & Theater          Electronics|Portable Audio & Video|Radios  \n",
       " 4       All Electronics  Electronics|Computers & Accessories|Computer C...  )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a6b53",
   "metadata": {},
   "source": [
    "## Find out all the genres used (for categorical columns)\n",
    "\n",
    "- USER_COL, ITEM_COL are numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a94d60bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5613183/5613183 [01:11<00:00, 79034.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cols = [USER_COL, ITEM_COL] # label is rating, USER_COL, ITEM_COL followed by the categorical genres\n",
    "genres_set = set()\n",
    "\n",
    "with tqdm(total=data.shape[0]) as pbar:\n",
    "    for _, row in data.iterrows():\n",
    "        genres = row[ITEM_FEAT_COL]\n",
    "        genres = genres.strip()\n",
    "        assert((genres != '') and (len(genres) > 0))\n",
    "        genres = genres.split('|')\n",
    "        for genre in genres:\n",
    "            genres_set.add(genre)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09b8517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userID', 'itemID', 'Accessories', 'Accessories & Supplies', 'All Electronics', 'Amazon Devices', 'Apple Products', 'Audio & Video Accessories', 'Automotive', 'Camera & Photo', 'Car & Vehicle Electronics', 'Car Electronics', 'Cell Phones & Accessories', 'Clothing, Shoes & Jewelry', 'Computer Accessories & Peripherals', 'Computer Components', 'Computers', 'Computers & Accessories', 'Controllers', 'Electrical', 'Electronics', 'GPS & Navigation', 'Home & Kitchen', 'Home Audio', 'Home Audio & Theater', 'Industrial & Scientific', 'Laptop Accessories', 'Musical Instruments', 'Office & School Supplies', 'Office Electronics', 'Office Products', 'Portable Audio & Accessories', 'Portable Audio & Video', 'Sports & Fitness', 'Sports & Outdoors', 'Tools & Home Improvement', 'Toys & Games', 'Video Games']\n"
     ]
    }
   ],
   "source": [
    "lst_genres = list(genres_set)\n",
    "lst_genres = sorted(lst_genres)\n",
    "        \n",
    "for genre in lst_genres:\n",
    "    cols.append(genre)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce6fd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the two dictionaries for model serving\n",
    "with open(DATA_DIR + 'xdeepfm/lst_genres.pkl', 'wb') as f:\n",
    "    pickle.dump(lst_genres, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fc21af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the two dictionaries for model serving\n",
    "with open(DATA_DIR + 'xdeepfm/lst_genres.pkl', 'rb') as f:\n",
    "    lst_genres = pickle.load(f)\n",
    "cols = [USER_COL, ITEM_COL]\n",
    "for genre in lst_genres:\n",
    "    cols.append(genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f751d22b",
   "metadata": {},
   "source": [
    "## Prepare the feature set\n",
    "\n",
    "- Ref: https://github.com/Leavingseason/xDeepFM/tree/master/exdeepfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b94cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5613183/5613183 [01:42<00:00, 55009.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cat_feat_cnt = defaultdict(int)\n",
    "\n",
    "with tqdm(total=data.shape[0]) as pbar:\n",
    "    for _, row in data.iterrows():\n",
    "        genres = row[ITEM_FEAT_COL]\n",
    "        genres = genres.strip()\n",
    "        assert((genres != '') and (len(genres) > 0))\n",
    "        genres = genres.split('|')\n",
    "\n",
    "        for col in cols[2:]:\n",
    "            if col not in genres:\n",
    "                cat_feat_cnt[col+'#absent'] += 1\n",
    "            else:\n",
    "                cat_feat_cnt[col+'#1'] += 1\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d14ca68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5613183/5613183 [02:02<00:00, 45844.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "feat_set = set()\n",
    "T = 4\n",
    "\n",
    "with tqdm(total=data.shape[0]) as pbar:\n",
    "    for _, row in data.iterrows():\n",
    "        user = row[USER_COL]\n",
    "        item = row[ITEM_COL]\n",
    "\n",
    "        feat_set.add('user#'+str(user))\n",
    "        feat_set.add('item#'+str(item))\n",
    "\n",
    "        genres = row[ITEM_FEAT_COL]\n",
    "        genres = genres.strip()\n",
    "        assert((genres != '') and (len(genres) > 0))\n",
    "        genres = genres.split('|')\n",
    "\n",
    "        for col in cols[2:]:\n",
    "            if col not in genres:\n",
    "                feat_set.add(col+'#absent')\n",
    "            else:\n",
    "                feat = col + '#1'\n",
    "                assert(cat_feat_cnt[feat] > T) # we don't need to worry about features that occur infrequently\n",
    "                feat_set.add(feat)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980b2c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "894465"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda63624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the two dictionaries for model serving\n",
    "with open(DATA_DIR + 'xdeepfm/feat_set.pkl', 'wb') as f:\n",
    "    pickle.dump(feat_set, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b922b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + 'xdeepfm/feat_set.pkl', 'rb') as f:\n",
    "    feat_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0833ce4",
   "metadata": {},
   "source": [
    "## Split into train, valid, test using python_chrono_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ded3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.datasets.python_splitters import python_chrono_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a89f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = python_chrono_split(data, [0.8,0.1,0.1], col_timestamp='unixTimeStamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ab68631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4519730, 9), (562550, 9), (530903, 9))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13a2bd",
   "metadata": {},
   "source": [
    "#### Using python_chrono_split has a better distribution\n",
    "\n",
    "- Note that we don't have enough reviewers that have given more than two reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5f6bc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830668, 426100, 418307)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['userID'].nunique(), valid['userID'].nunique(), test['userID'].nunique(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "298ef64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63725, 57569, 53917)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['itemID'].nunique(), valid['itemID'].nunique(), test['itemID'].nunique(), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d27726",
   "metadata": {},
   "source": [
    "#### When compared to simply chopping off the datasets into 80:10:10 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af549e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5613183 4490546 5051864\n"
     ]
    }
   ],
   "source": [
    "total_line_cnt = data.shape[0]\n",
    "train_line_cnt = int(0.8*total_line_cnt)\n",
    "val_line_cnt = int(0.9*total_line_cnt)\n",
    "print(\"total\", total_line_cnt, train_line_cnt, val_line_cnt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fb4c4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759281, 63314)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:train_line_cnt]['userID'].nunique(), data.iloc[:train_line_cnt]['itemID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5be29d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248228, 48176)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[train_line_cnt:val_line_cnt]['userID'].nunique(), data.iloc[train_line_cnt:val_line_cnt]['itemID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb94a901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250479, 44203)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[val_line_cnt:]['userID'].nunique(), data.iloc[val_line_cnt:]['itemID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e06a95",
   "metadata": {},
   "source": [
    "### Back to building the FFM format for train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dcc733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat dict num: 894465\n"
     ]
    }
   ],
   "source": [
    "feat_index = dict()\n",
    "for index, feat in enumerate(feat_set, start=1):\n",
    "    feat_index[feat] = index\n",
    "    # print(index, feat)\n",
    "print('feat dict num:', len(feat_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1dc11d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field dict num: 38\n"
     ]
    }
   ],
   "source": [
    "field_index = dict()\n",
    "field_list = cols\n",
    "\n",
    "for index, field in enumerate(field_list, start=1):\n",
    "    field_index[field] = index\n",
    "print('field dict num:', len(field_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f31023ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the two dictionaries for model serving\n",
    "with open(DATA_DIR + 'xdeepfm/feat_index.pkl', 'wb') as f:\n",
    "    pickle.dump(feat_index, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(DATA_DIR + 'xdeepfm/field_index.pkl', 'wb') as f:\n",
    "    pickle.dump(field_index, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b0e6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + 'xdeepfm/feat_index.pkl', 'rb') as f:\n",
    "    feat_index = pickle.load(f)\n",
    "with open(DATA_DIR + 'xdeepfm/field_index.pkl', 'rb') as f:\n",
    "    field_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f34f177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4519730/4519730 [02:25<00:00, 31025.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 562550/562550 [00:18<00:00, 30613.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 530903/530903 [00:17<00:00, 30781.72it/s]\n"
     ]
    }
   ],
   "source": [
    "dst_train_path = DATA_DIR + 'xdeepfm/amzn_e_train.txt'\n",
    "dst_valid_path = DATA_DIR + 'xdeepfm/amzn_e_valid.txt'\n",
    "dst_test_path =  DATA_DIR + 'xdeepfm/amzn_e_test.txt'\n",
    "\n",
    "def gen_ffm_data(path, df):\n",
    "    out_f = open(path, 'w')\n",
    "    with tqdm(total = df.shape[0]) as pbar:\n",
    "        for _,row in df.iterrows():\n",
    "            feats = []\n",
    "            feats.append(str(int(row['rating'])))\n",
    "\n",
    "            feats.append(str(field_index[USER_COL]) + ':' + str(feat_index['user#' + str(row[USER_COL])]) + ':1')\n",
    "            feats.append(str(field_index[ITEM_COL]) + ':' + str(feat_index['item#' + str(row[ITEM_COL])]) + ':1')\n",
    "\n",
    "            genres = row[ITEM_FEAT_COL]\n",
    "            genres = genres.strip()\n",
    "            assert((genres != '') and (len(genres) > 0))\n",
    "            genres = genres.split('|')\n",
    "\n",
    "            for col in cols[2:]:\n",
    "                if col not in genres:\n",
    "                    feat = col + '#absent'\n",
    "                else:\n",
    "                    feat = col + '#1'\n",
    "                feats.append(str(field_index[col]) + ':' + str(feat_index[feat]) + ':1')\n",
    "\n",
    "            out_f.write(' '.join(feats) + '\\n')\n",
    "            pbar.update(1)\n",
    "    out_f.close()\n",
    "gen_ffm_data(dst_train_path, train)\n",
    "gen_ffm_data(dst_valid_path, valid)\n",
    "gen_ffm_data(dst_test_path, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df655605",
   "metadata": {},
   "source": [
    "## Generate the test data samples for ndcg, hit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef13487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grp = train[['userID', 'itemID']].groupby('userID').agg(list)\n",
    "# valid_grp = valid[['userID', 'itemID']].groupby('userID', as_index=False).agg(list)\n",
    "all_items_set = set(data['itemID'].unique())\n",
    "\n",
    "items_df = train[[ITEM_COL, ITEM_FEAT_COL]].drop_duplicates([ITEM_COL]).copy()\n",
    "items_df.set_index(ITEM_COL, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cecc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import random\n",
    "\n",
    "NUM_NEG_SAMPLES = 50\n",
    "RANDOM_SEED = 42\n",
    "N_WORKERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4f42500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10  106180106180 (106180, 9) 2\n",
      " 212360 3212360(106180, 9)  \n",
      "318540318540  (106180, 9)424720\n",
      "4  (106180, 9)424720 \n",
      "530903 (106183, 9)\n",
      "$@%#!%#@!$#%!@$#@%!$#@!$%!#@$%!#@$%#!@$%!#@$%!#@$%"
     ]
    }
   ],
   "source": [
    "processors = []\n",
    "\n",
    "def sample_function(train_grp, test, items_df, field_index, feat_index, cols, i, num_workers, seed, data_dir):\n",
    "    nrows = test.shape[0]\n",
    "    each = nrows // num_workers\n",
    "    start = i*each\n",
    "    end = nrows if i == num_workers - 1 else (i+1)*each\n",
    "    sym = ['!','@','#','$','%']\n",
    "\n",
    "    print(i, start, end, test.iloc[start:end].shape)\n",
    "    random.seed(seed)\n",
    "    tst_w_neg_samples_path = data_dir + f'xdeepfm/amzn_e_tst_w_neg{i}.txt'\n",
    "    out_f = open(tst_w_neg_samples_path, 'w')\n",
    "    \n",
    "    j = 0\n",
    "    line_cnt = 0\n",
    "    for _, row in test.iloc[start:end].iterrows():\n",
    "        u = row[USER_COL]\n",
    "        positive_item = row[ITEM_COL]\n",
    "\n",
    "        feats = []\n",
    "        feats.append(str(int(row['rating'])))\n",
    "\n",
    "        feats.append(str(field_index[USER_COL]) + ':' + str(feat_index['user#' + str(u)]) + ':1')\n",
    "        feats.append(str(field_index[ITEM_COL]) + ':' + str(feat_index['item#' + str(positive_item)]) + ':1')\n",
    "\n",
    "        genres = row[ITEM_FEAT_COL]\n",
    "        genres = genres.strip()\n",
    "        assert((genres != '') and (len(genres) > 0))\n",
    "        genres = genres.split('|')\n",
    "\n",
    "        for col in cols[2:]:\n",
    "            if col not in genres:\n",
    "                feat = col + '#absent'\n",
    "            else:\n",
    "                feat = col + '#1'\n",
    "            feats.append(str(field_index[col]) + ':' + str(feat_index[feat]) + ':1')\n",
    "        out_f.write(' '.join(feats) + '\\n')\n",
    "        line_cnt += 1\n",
    "        \n",
    "        items_seen_set = set(train_grp.loc[u][ITEM_COL])\n",
    "        items_not_seen_lst = list(all_items_set - items_seen_set)\n",
    "        \n",
    "        cnt = 0\n",
    "        neg_items = set()\n",
    "        while cnt < NUM_NEG_SAMPLES:\n",
    "            neg_item = random.choice(items_not_seen_lst)\n",
    "            if neg_item == positive_item or neg_item in neg_items:\n",
    "                continue\n",
    "\n",
    "            cnt += 1\n",
    "            neg_items.add(neg_item)\n",
    "            \n",
    "            feats = []\n",
    "            feats.append(str(0))\n",
    "            \n",
    "            feats.append(str(field_index[USER_COL]) + ':' + \n",
    "                         str(feat_index['user#' + str(u)]) + ':1')\n",
    "            feats.append(str(field_index[ITEM_COL]) + ':' + \n",
    "                         str(feat_index['item#' + str(neg_item)]) + ':1')\n",
    "            \n",
    "            item_data = items_df.loc[neg_item]\n",
    "            assert(item_data.shape[0] != 0)\n",
    "            \n",
    "            genres = item_data[ITEM_FEAT_COL]\n",
    "            genres = genres.strip()\n",
    "            assert((genres != '') and (len(genres) > 0))\n",
    "            genres = genres.split('|')\n",
    "\n",
    "            for col in cols[2:]:\n",
    "                if col not in genres:\n",
    "                    feat = col + '#absent'\n",
    "                else:\n",
    "                    feat = col + '#1'\n",
    "                feats.append(str(field_index[col]) + ':' + str(feat_index[feat]) + ':1')\n",
    "            out_f.write(' '.join(feats) + '\\n')\n",
    "            line_cnt += 1\n",
    "        j += 1\n",
    "        if j % 10_000 == 0:\n",
    "            assert(line_cnt == j*51)\n",
    "            print(sym[i], end='')\n",
    "        \n",
    "    out_f.close()    \n",
    "    \n",
    "    \n",
    "for i in range(N_WORKERS):\n",
    "    processors.append(\n",
    "        Process(\n",
    "            target = sample_function,\n",
    "            args = (train_grp, test, items_df, \n",
    "                    field_index, feat_index, cols, i, N_WORKERS, RANDOM_SEED, DATA_DIR)\n",
    "        ))\n",
    "    # processors[-1].daemon = True\n",
    "    processors[-1].start()\n",
    "for i in range(N_WORKERS):\n",
    "    processors[i].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72e72c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530903, 9)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b26168",
   "metadata": {},
   "source": [
    "# Old code!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d430dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********!*********!*********!*********!*********!******"
     ]
    }
   ],
   "source": [
    "line_cnt = 0\n",
    "\n",
    "dst_train_path = DATA_DIR + 'xdeepfm/amzn_e_train.txt'\n",
    "dst_valid_path = DATA_DIR + 'xdeepfm/amzn_e_valid.txt'\n",
    "dst_test_path =  DATA_DIR + 'xdeepfm/amzn_e_test.txt'\n",
    "\n",
    "out_train = open(dst_train_path, 'w')\n",
    "out_valid = open(dst_valid_path, 'w')\n",
    "out_test = open(dst_test_path, 'w')\n",
    "out = out_train\n",
    "\n",
    "for _,row in data.iterrows():\n",
    "    feats = []\n",
    "    feats.append(str(int(row['rating'])))\n",
    "\n",
    "    feats.append(str(field_index[USER_COL]) + ':' + str(feat_index['user#' + str(row[USER_COL])]) + ':1')\n",
    "    feats.append(str(field_index[ITEM_COL]) + ':' + str(feat_index['item#' + str(row[ITEM_COL])]) + ':1')\n",
    "\n",
    "    genres = row[ITEM_FEAT_COL]\n",
    "    genres = genres.strip()\n",
    "    assert((genres != '') and (len(genres) > 0))\n",
    "    genres = genres.split('|')\n",
    "    \n",
    "    for col in cols[2:]:\n",
    "        if col not in genres:\n",
    "            feat = col + '#absent'\n",
    "        else:\n",
    "            feat = col + '#1'\n",
    "        feats.append(str(field_index[col]) + ':' + str(feat_index[feat]) + ':1')\n",
    "  \n",
    "    out.write(' '.join(feats) + '\\n')\n",
    "        \n",
    "    line_cnt += 1\n",
    "    if line_cnt % 100000 == 0:\n",
    "        if line_cnt %1000000 == 0:\n",
    "            print('!',end='')\n",
    "        else:\n",
    "            print('*', end='')\n",
    "    if (line_cnt >= train_line_cnt) and (out == out_train):\n",
    "        out = out_valid\n",
    "    elif (line_cnt >= val_line_cnt) and (out == out_valid):\n",
    "        out = out_test\n",
    "\n",
    "out_train.close()\n",
    "out_valid.close()\n",
    "out_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab6987a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830668, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = data.drop_duplicates(USER_COL)[[USER_COL]].reset_index(drop=True)\n",
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ebe72d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63725, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = data.drop_duplicates(ITEM_COL)[[ITEM_COL, ITEM_FEAT_COL]].reset_index(drop=True)\n",
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25941b90",
   "metadata": {},
   "source": [
    "## Test set for ranking (only for movielens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a0f9f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = data.drop_duplicates(USER_COL)[[USER_COL]].reset_index(drop=True)\n",
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d67a8b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = data.drop_duplicates(ITEM_COL)[[ITEM_COL, ITEM_FEAT_COL]].reset_index(drop=True)\n",
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6475a4",
   "metadata": {},
   "source": [
    "### Following merge will fail for Electronics dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4461eaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>682</td>\n",
       "      <td>Horror|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>317</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>678</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586121</th>\n",
       "      <td>107</td>\n",
       "      <td>1579</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586122</th>\n",
       "      <td>107</td>\n",
       "      <td>830</td>\n",
       "      <td>Action|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586123</th>\n",
       "      <td>107</td>\n",
       "      <td>1569</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586124</th>\n",
       "      <td>107</td>\n",
       "      <td>1236</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586125</th>\n",
       "      <td>107</td>\n",
       "      <td>1580</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1586126 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  itemID                    genre\n",
       "0            31     682  Horror|Mystery|Thriller\n",
       "1            31      15                    Drama\n",
       "2            31     317                    Drama\n",
       "3            31     678           Drama|Thriller\n",
       "4            31      66           Comedy|Romance\n",
       "...         ...     ...                      ...\n",
       "1586121     107    1579                 Thriller\n",
       "1586122     107     830  Action|Mystery|Thriller\n",
       "1586123     107    1569             Comedy|Drama\n",
       "1586124     107    1236                    Drama\n",
       "1586125     107    1580                  Romance\n",
       "\n",
       "[1586126 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[\"key\"] = 1\n",
    "items[\"key\"] = 1\n",
    "users_items = users.merge(items, on=\"key\")\n",
    "\n",
    "users.drop(\"key\", axis=1, inplace=True)\n",
    "items.drop(\"key\", axis=1, inplace=True)\n",
    "users_items.drop(\"key\", axis=1, inplace=True)\n",
    "\n",
    "users_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78c0546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items = users_items.loc[\n",
    "        ~users_items.set_index([USER_COL, ITEM_COL]).index.isin(\n",
    "            data.set_index([USER_COL, ITEM_COL]).index\n",
    "        )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c778995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>317</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>678</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>88</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586121</th>\n",
       "      <td>107</td>\n",
       "      <td>1579</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586122</th>\n",
       "      <td>107</td>\n",
       "      <td>830</td>\n",
       "      <td>Action|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586123</th>\n",
       "      <td>107</td>\n",
       "      <td>1569</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586124</th>\n",
       "      <td>107</td>\n",
       "      <td>1236</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586125</th>\n",
       "      <td>107</td>\n",
       "      <td>1580</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1486126 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  itemID                    genre\n",
       "1            31      15                    Drama\n",
       "2            31     317                    Drama\n",
       "3            31     678           Drama|Thriller\n",
       "4            31      66           Comedy|Romance\n",
       "5            31      88           Comedy|Romance\n",
       "...         ...     ...                      ...\n",
       "1586121     107    1579                 Thriller\n",
       "1586122     107     830  Action|Mystery|Thriller\n",
       "1586123     107    1569             Comedy|Drama\n",
       "1586124     107    1236                    Drama\n",
       "1586125     107    1580                  Romance\n",
       "\n",
       "[1486126 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b2bbe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_test_nolabel = DATA_DIR + 'movielens_100k_test_no_label.txt'\n",
    "\n",
    "out = open(dst_test_nolabel, 'w')\n",
    "\n",
    "for _,row in users_items.iterrows():\n",
    "    feats = []\n",
    "\n",
    "    feats.append(str(field_index[USER_COL]) + ':' + str(feat_index['user#' + str(row[USER_COL])]) + ':1')\n",
    "    feats.append(str(field_index[ITEM_COL]) + ':' + str(feat_index['item#' + str(row[ITEM_COL])]) + ':1')\n",
    "\n",
    "    genres = row[ITEM_FEAT_COL]\n",
    "    genres = genres.strip()\n",
    "    assert((genres != '') and (len(genres) > 0))\n",
    "    genres = genres.split('|')\n",
    "    \n",
    "    for col in cols[2:]:\n",
    "        if col not in genres:\n",
    "            feat = col + '#absent'\n",
    "        else:\n",
    "            feat = col + '#1'\n",
    "        feats.append(str(field_index[col]) + ':' + str(feat_index[feat]) + ':1')\n",
    "  \n",
    "    out.write(' '.join(feats) + '\\n')\n",
    "        \n",
    "    line_cnt += 1\n",
    "#     if line_cnt % 100000 == 0:\n",
    "#         if line_cnt %1000000 == 0:\n",
    "#             print('!',end='')\n",
    "#         else:\n",
    "#             print('*', end='')\n",
    "\n",
    "\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de5a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
