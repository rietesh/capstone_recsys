{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44944d2f",
   "metadata": {},
   "source": [
    "# Prepare for wide_deep\n",
    "\n",
    "1. Restart the kernel\n",
    "2. Read the ratings and items dataframes\n",
    "3. Prepare Electronics, Home and Games datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6396a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "MIN_REVIEWS = 20\n",
    "\n",
    "DATA_DIR = '/home/shiv/Documents/DataScience/Capstone/Data/wide_deep/'\n",
    "ratings_df = pd.read_csv(DATA_DIR + f'all_reviews_{MIN_REVIEWS}.csv', header=None)\n",
    "ratings_df.columns = ['reviewerID', 'asin', 'rating', 'unixTimeStamp']     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7628de",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = pd.read_csv(DATA_DIR + f'all_meta_{MIN_REVIEWS}.csv', header=None)\n",
    "# items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12391d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df.columns=['asin','price','title','main_cat','category']\n",
    "items_df['category'].fillna('', inplace=True)\n",
    "items_df['price'].fillna('$$$', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01aa035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample to show how to drop a main category\n",
    "\n",
    "# mag_subs = items_df[items_df['main_cat']=='Magazine Subscriptions']['asin'].values\n",
    "# ratings_df=ratings_df[~ratings_df['asin'].isin(mag_subs)]\n",
    "# items_df=items_df[~items_df['asin'].isin(mag_subs)]\n",
    "# ratings_df.reset_index(inplace=True,drop=True)\n",
    "# items_df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0cf3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(items_df['main_cat'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4fb7b4",
   "metadata": {},
   "source": [
    "## Use all the main categories; if only specific main categories are needed, skip to [Electronics](#electronics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a11847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting reviewerID to userID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 38007219/38007219 [07:52<00:00, 80368.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged dataframe (38007219, 8)\n",
      "Converting asin to itemID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 484062/484062 [00:07<00:00, 62080.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Step 3: convert reviewerID to userID (0 based)\n",
    "print(\"Converting reviewerID to userID\")\n",
    "reviewers_dict = {}\n",
    "reviewer_id = 0\n",
    "with tqdm(total=ratings_df.shape[0]) as pbar:\n",
    "    for _, row in ratings_df.iterrows():\n",
    "        if row['reviewerID'] not in reviewers_dict:\n",
    "            reviewers_dict[row['reviewerID']] = reviewer_id\n",
    "            reviewer_id += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "ratings_df['userID'] = ratings_df['reviewerID'].apply(lambda x: reviewers_dict[x])\n",
    "\n",
    "# Step 4: save the reviewerID dict (perhaps for UI)\n",
    "users_pkl_path = DATA_DIR + f'users_all_{MIN_REVIEWS}.pkl'\n",
    "\n",
    "with open(users_pkl_path, 'wb') as handle:\n",
    "    pickle.dump(reviewers_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "del reviewers_dict\n",
    "ratings_df.drop(columns=['reviewerID'], inplace=True) # we will henceforth use userID\n",
    "\n",
    "# Step 5: left merge the ratings with items on asin\n",
    "data = ratings_df.merge(items_df, on=['asin'], how='left')\n",
    "print(\"merged dataframe\", data.shape)\n",
    "data['category'] = data['category'].astype('string')\n",
    "\n",
    "del ratings_df\n",
    "\n",
    "# Step 6: convert asin to itemID (0 based)\n",
    "print(\"Converting asin to itemID\")\n",
    "items_dict = {}\n",
    "item_id = 0\n",
    "\n",
    "with tqdm(total=items_df.shape[0]) as pbar:\n",
    "    for _, row in items_df.iterrows():\n",
    "        if row['asin'] not in items_dict:\n",
    "            items_dict[row['asin']] = item_id\n",
    "            item_id += 1\n",
    "        pbar.update(1)\n",
    "data['itemID'] = data['asin'].apply(lambda x: items_dict[x])\n",
    "\n",
    "# Step 7: save the itemID dict (for UI)\n",
    "items_pkl_path = DATA_DIR + f'items_all_{MIN_REVIEWS}.pkl'\n",
    "\n",
    "with open(items_pkl_path, 'wb') as handle:\n",
    "    pickle.dump(items_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "del items_dict\n",
    "data.drop(columns=['asin'], inplace=True) # we will henceforth use itemID\n",
    "\n",
    "tqdm.pandas()\n",
    "lst_main_cat = items_df.main_cat.unique()\n",
    "\n",
    "# Step 8: add genre; \n",
    "# currently, consider the main categories or if an item in category matches the main category list\n",
    "data['genre'] = ''\n",
    "\n",
    "def update_category(row):\n",
    "    categories = row['category']\n",
    "    new_cat = []\n",
    "    new_cat.append(row['main_cat'])\n",
    "    # print(categories)\n",
    "    for cat in categories.split('|'):\n",
    "        if cat.strip() != '' and (cat in lst_main_cat):\n",
    "            new_cat.append(cat)\n",
    "    row['genre'] = '|'.join(new_cat)\n",
    "    return row\n",
    "data = data.progress_apply(update_category, axis=1)\n",
    "\n",
    "# Step 9: save the prepared dataset to be used by wide_deep model\n",
    "data.drop(columns=['category'], inplace=True)\n",
    "data.sort_values('unixTimeStamp', inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "data = data[['userID','itemID', 'rating','genre','unixTimeStamp','title','price','main_cat','category']]\n",
    "data.to_csv(DATA_DIR + f'wide_deep_amzn_all_{MIN_REVIEWS}.csv', \n",
    "             header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f03340",
   "metadata": {},
   "source": [
    "<a id=\"electronics\"></a>\n",
    "# Prepare Electronics, Home, Games datasets\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Filter the items dataframe to remove all items whose main_cat is not in the list of main_categories for each umbrella category (e.g. Electronics)\n",
    "2. Filter the rating dataframe to remove all reviews that do not belong to the list of item IDs left in the items dataframe after step 1.\n",
    "3. Convert hexadecimal reviewerID in the ratings dataframe to userID (0 based)\n",
    "4. Save the reviewerID dict in a pkl file\n",
    "5. Left merge ratings and items filtered dataframe on asin (hexadecimal)\n",
    "6. Convert hexadecimal asin to itemID (0 based)\n",
    "7. Save the itemID dict (for UI) in a pkl file\n",
    "8. Add genre; currently, consider the main categories or if an item in category matches the sub category list\n",
    "9. Save the prepared dataset for use by modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "857e83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "DATA_DIR = '/home/shiv/Documents/DataScience/Capstone/Data/wide_deep/'\n",
    "\n",
    "def prepare_dataset(lst_main_cat, lst_sub_cat, items_df, ratings_df, dataset):\n",
    "    data_dir = DATA_DIR + dataset + '/'\n",
    "    \n",
    "    # Step 1: filter the items dataframe\n",
    "    items_filtered_df = items_df[items_df['main_cat'].isin(lst_main_cat)].copy()\n",
    "    items_filtered_ids = items_filtered_df['asin'].values\n",
    "\n",
    "    # Step 2: filter the ratings dataframe\n",
    "    ratings_filtered_df = ratings_df[ratings_df['asin'].isin(items_filtered_ids)].copy()\n",
    "    \n",
    "    print(dataset)\n",
    "    print(\"Num ratings:\", ratings_filtered_df.shape[0])\n",
    "    print(\"users\", ratings_filtered_df['reviewerID'].nunique(), \"items\", ratings_filtered_df['asin'].nunique())\n",
    "    \n",
    "    # Step 3: convert reviewerID to userID (0 based)\n",
    "    reviewers_dict = {}\n",
    "    reviewer_id = 0\n",
    "    for _, row in ratings_filtered_df.iterrows():\n",
    "        if row['reviewerID'] not in reviewers_dict:\n",
    "            reviewers_dict[row['reviewerID']] = reviewer_id\n",
    "            reviewer_id += 1\n",
    "            \n",
    "    ratings_filtered_df['userID'] = ratings_filtered_df['reviewerID'].apply(lambda x: reviewers_dict[x])\n",
    "\n",
    "    # Step 4: save the reviewerID dict (perhaps for UI)\n",
    "    users_pkl_path = data_dir + f'users_{dataset[0].lower()}_{MIN_REVIEWS}.pkl'\n",
    "\n",
    "    with open(users_pkl_path, 'wb') as handle:\n",
    "        pickle.dump(reviewers_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    ratings_filtered_df.drop(columns=['reviewerID'], inplace=True) # we will henceforth use userID\n",
    "\n",
    "    # Step 5: left merge the ratings with items on asin\n",
    "    data = ratings_filtered_df.merge(items_filtered_df, on=['asin'], how='left')\n",
    "    print(\"merged dataframe\", data.shape)\n",
    "    data['category'] = data['category'].astype('string')\n",
    "    \n",
    "    # Step 6: convert asin to itemID (0 based)\n",
    "    items_dict = {}\n",
    "    item_id = 0\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        if row['asin'] not in items_dict:\n",
    "            items_dict[row['asin']] = item_id\n",
    "            item_id += 1\n",
    "    data['itemID'] = data['asin'].apply(lambda x: items_dict[x])\n",
    "    \n",
    "    # Step 7: save the itemID dict (for UI)\n",
    "    items_pkl_path = data_dir + f'items_{dataset[0].lower()}_{MIN_REVIEWS}.pkl'\n",
    "\n",
    "    with open(items_pkl_path, 'wb') as handle:\n",
    "        pickle.dump(items_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)        \n",
    "    data.drop(columns=['asin'], inplace=True) # we will henceforth use itemID\n",
    "    \n",
    "    # Step 8: add genre; \n",
    "    # currently, consider the main categories or if an item in category matches the sub category list\n",
    "    data['genre'] = ''\n",
    "\n",
    "    def update_category(row):\n",
    "        categories = row['category']\n",
    "        new_cat = []\n",
    "        new_cat.append(row['main_cat'])\n",
    "        # print(categories)\n",
    "        for cat in categories.split('|'):\n",
    "            if cat.strip() != '' and ((cat in lst_main_cat) or (cat in lst_sub_cat)):\n",
    "                new_cat.append(cat)\n",
    "        row['genre'] = '|'.join(new_cat)\n",
    "        return row\n",
    "    data = data.apply(update_category, axis=1)\n",
    "    \n",
    "    # Step 9: save the prepared dataset to be used by wide_deep model\n",
    "    # data.drop(columns=['category'], inplace=True)\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data = data[['userID','itemID', 'rating','genre','unixTimeStamp','title','price','main_cat','category']]\n",
    "    data.to_csv(data_dir + f'wide_deep_amzn_{dataset[0].lower()}_{MIN_REVIEWS}.csv', \n",
    "                 header=False, index=False)\n",
    "    \n",
    "    del items_filtered_df\n",
    "    del ratings_filtered_df\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4597070",
   "metadata": {},
   "source": [
    "### Electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cefa68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronics\n",
      "Num ratings: 5613183\n",
      "users 830668 items 63725\n",
      "merged dataframe (5613183, 8)\n"
     ]
    }
   ],
   "source": [
    "# main_cat = 'Electronics'\n",
    "lst_main_cat = ['All Electronics', 'Amazon Devices', 'Apple Products', \n",
    "                 'Camera & Photo', 'Car Electronics', 'Cell Phones & Accessories', 'Computers',\n",
    "                 'Electronics', 'GPS & Navigation', 'Home Audio & Theater', 'Industrial & Scientific',\n",
    "                 'Portable Audio & Accessories']\n",
    "\n",
    "lst_sub_cat = ['Accessories','Computers & Accessories','Office Products','Video Games',\n",
    "               'Accessories & Supplies','Tools & Home Improvement','Computer Accessories & Peripherals',\n",
    "               'Audio & Video Accessories', 'Automotive', 'Office & School Supplies',\n",
    "               'Car & Vehicle Electronics', 'Industrial & Scientific','Sports & Outdoors','Office Electronics',\n",
    "               'Home & Kitchen','Musical Instruments','Portable Audio & Video','Electrical',\n",
    "               'Clothing, Shoes & Jewelry','Toys & Games','Laptop Accessories','Home Audio',\n",
    "               'Controllers','Computer Components','Sports & Fitness']\n",
    "prepare_dataset(lst_main_cat, lst_sub_cat, items_df, ratings_df, \"Electronics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c15c47",
   "metadata": {},
   "source": [
    "### Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca0f2129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home\n",
      "Num ratings: 7575829\n",
      "users 882963 items 92562\n",
      "merged dataframe (7575829, 8)\n"
     ]
    }
   ],
   "source": [
    "# main_cat = 'Home'\n",
    "lst_main_cat = ['Amazon Home', 'Appliances', 'Home & Kitchen', \n",
    "                'Patio, Lawn & Garden', 'Tools & Home Improvement']\n",
    "\n",
    "lst_sub_cat = ['Kitchen & Dining', 'Industrial & Scientific', 'Power & Hand Tools',\n",
    "               'Automotive', 'Arts, Crafts & Sewing', 'Office Products',\n",
    "               'Electronics', 'Sports & Outdoors', 'Home Dcor', 'Accessories', 'Hand Tools',\n",
    "               'Office & School Supplies', 'Gardening & Lawn Care',\n",
    "               'Hardware', 'Storage & Organization', 'Lighting & Ceiling Fans',\n",
    "               'Kitchen Utensils & Gadgets', 'Electrical', 'Furniture', 'Pet Supplies',\n",
    "               'Building Supplies', 'Bedding', 'Sports & Fitness', 'Safety & Security',\n",
    "               'Outdoor Recreation', 'Power Tool Parts & Accessories', 'Kitchen & Bath Fixtures',\n",
    "               'Parts & Accessories', 'Small Appliances', 'Replacement Parts',\n",
    "               'Crafting', 'Sewing', 'Tools & Equipment', 'Outdoor Dcor', 'Patio Furniture & Accessories',\n",
    "               'Grills & Outdoor Cooking', 'Power Tools', 'Rough Plumbing', 'Bath',\n",
    "               'Bakeware', 'Accessories & Supplies', 'Heating, Cooling & Air Quality',\n",
    "               'Outdoor Power Tools', 'Outdoor Lighting', 'Paint, Wall Treatments & Supplies',\n",
    "               'Home Dcor Accents', 'Pools, Hot Tubs & Supplies', 'Bathroom Fixtures',\n",
    "               'Test, Measure & Inspect', 'Bathroom Accessories', 'Personal Protective Equipment',\n",
    "               'Fasteners', 'Vacuums & Floor Care', 'Clothing & Closet Storage', 'Exterior Accessories',\n",
    "               'Replacement Parts & Accessories', 'Desk Accessories & Workspace Organizers',\n",
    "               'Outdoor Cooking Tools & Accessories', 'HVAC']\n",
    "prepare_dataset(lst_main_cat, lst_sub_cat, items_df, ratings_df, \"Home\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afde184",
   "metadata": {},
   "source": [
    "### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f8e2c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games\n",
      "Num ratings: 3735507\n",
      "users 748773 items 56219\n",
      "merged dataframe (3735507, 8)\n"
     ]
    }
   ],
   "source": [
    "# main_cat = 'Games'\n",
    "lst_main_cat = ['Sports & Outdoors', 'Toys & Games', 'Video Games']\n",
    "lst_sub_cat = ['Sports & Fitness', 'Accessories', 'Clothing, Shoes & Jewelry', 'Home & Kitchen',\n",
    "               'Outdoor Recreation', 'Clothing', 'Electronics', 'Games', \n",
    "               'Sports & Outdoor Play', 'Cycling', 'Exercise & Fitness', 'Camping & Hiking',\n",
    "               'Leisure Sports & Game Room', 'Hunting & Fishing', 'Retro Gaming & Microconsoles',\n",
    "               'Costumes & Accessories', 'Dress Up & Pretend Play', 'Shoes', 'Golf', 'Hobbies',\n",
    "               'Water Sports', 'Controllers', 'Xbox One', 'PlayStation 3', 'Motorcycle & Powersports',\n",
    "               'Arts & Crafts', 'Replacement Parts', 'Xbox 360', 'Other Sports', 'Crafting',\n",
    "               'Wii', 'Learning & Education', 'Sports', 'Active', 'Consoles',\n",
    "               'Painting, Drawing & Art Supplies', 'Audio & Video Accessories', 'Nintendo 3DS & 2DS',\n",
    "               'Athletic', 'Skates, Skateboards & Scooters', 'Building Toys', 'Building Sets']\n",
    "prepare_dataset(lst_main_cat, lst_sub_cat, items_df, ratings_df, \"Games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e2f0e",
   "metadata": {},
   "source": [
    "# Code to discover relevant sub categories to build the lst_sub_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98301b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "ratings_g_df = pd.read_csv(DATA_DIR + 'wide_deep_amzn_g_20.csv', header=None, low_memory=False)\n",
    "ratings_g_df.columns=['userID','itemID', 'rating','genre','unixTimeStamp','title','price','main_cat','category']\n",
    "ratings_g_df['category'].fillna('', inplace=True)\n",
    "ratings_g_df['price'].fillna('$$$', inplace=True)\n",
    "    \n",
    "lst = list(ratings_g_df['category'].unique())\n",
    "word_count = defaultdict(int)\n",
    "for l in lst:\n",
    "    for w in l.split('|'):\n",
    "        word_count[w] += 1\n",
    "dict(sorted(word_count.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579af3e1",
   "metadata": {},
   "source": [
    "# Additional datasets: Books, Health & Personal Care, Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d70047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_cat = 'Books'\n",
    "lst_main_cat = ['Books', 'Kindle', 'Audible audiobooks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e726516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_cat = 'Health & Personal Care'\n",
    "lst_main_cat = ['All Beauty', 'Health & Personal Care', 'Luxury Beauty']\n",
    "\n",
    "# main_cat = 'Fashion'\n",
    "lst_main_cat = ['Amazon Fashion', 'Clothing, Shoes & Jewelry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ac402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
