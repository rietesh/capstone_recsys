{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep Model for Amazon Products Recommendation\n",
    "\n",
    "<br>\n",
    "\n",
    "A linear model with a wide set of crossed-column (co-occurrence) features can memorize the feature interactions, while deep neural networks (DNN) can generalize the feature patterns through low-dimensional dense embeddings learned for the sparse features. \n",
    "\n",
    "[**Wide-and-deep**](https://arxiv.org/abs/1606.07792) learning jointly trains wide linear model and deep neural networks to combine the benefits of memorization and generalization for recommender systems.\n",
    "\n",
    "This notebook shows how to build and test the wide-and-deep model using [TensorFlow high-level Estimator API](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNLinearCombinedRegressor). With the [movie recommendation dataset](https://grouplens.org/datasets/movielens/), we quickly demonstrate following topics:\n",
    "1. How to prepare data\n",
    "2. Build the model\n",
    "3. Use log-hook to estimate performance while training\n",
    "4. Test the model and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.8.0\n",
      "GPUs:\n",
      " [{'device_name': 'NVIDIA GeForce RTX 3070', 'total_memory': 7982.3125, 'free_memory': 7365.6875}, {'device_name': 'NVIDIA GeForce RTX 3070', 'total_memory': 7982.3125, 'free_memory': 7816.0625}]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import numpy as np\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.utils.constants import (\n",
    "    DEFAULT_USER_COL as USER_COL, # userID\n",
    "    DEFAULT_ITEM_COL as ITEM_COL, # itemID\n",
    "    DEFAULT_RATING_COL as RATING_COL, # rating\n",
    "    DEFAULT_PREDICTION_COL as PREDICT_COL, # prediction\n",
    "    DEFAULT_GENRE_COL as ITEM_FEAT_COL, # features\n",
    "    SEED,\n",
    "    DEFAULT_K,\n",
    "    DEFAULT_THRESHOLD\n",
    ")\n",
    "\n",
    "from recommenders.utils import tf_utils, gpu_utils, plot\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.pandas_df_utils import user_item_pairs\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "import recommenders.evaluation.python_evaluation as evaluator\n",
    "import recommenders.models.wide_deep.wide_deep_utils as wide_deep\n",
    "\n",
    "print(\"Tensorflow Version:\", tf.__version__)\n",
    "print(\"GPUs:\\n\", gpu_utils.get_gpu_info())\n",
    "# tf.config.set_visible_devices([], 'GPU') # force to run on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"Parameters\"\"\"\n",
    "\n",
    "# Recommend top k items\n",
    "TOP_K = 10\n",
    "\n",
    "# Metrics to use for evaluation\n",
    "RANKING_METRICS = [\n",
    "    evaluator.ndcg_at_k.__name__,\n",
    "    evaluator.precision_at_k.__name__,\n",
    "]\n",
    "\n",
    "RATING_METRICS = [\n",
    "    evaluator.rmse.__name__,\n",
    "    evaluator.mae.__name__,\n",
    "]\n",
    "\n",
    "# Use session hook to evaluate model while training\n",
    "EVALUATE_WHILE_TRAINING = True\n",
    "\n",
    "RANDOM_SEED = SEED  # Set seed for deterministic result\n",
    "\n",
    "# Train and test set pickle file paths. If provided, use them. Otherwise, download the MovieLens dataset.\n",
    "DATA_DIR = '/home/shiv/Documents/DataScience/Capstone/Data/'\n",
    "EXPORT_DIR_BASE = './outputs/model'\n",
    "\n",
    "# Model checkpoints directory. If None, use temp-dir.\n",
    "MODEL_DIR = None\n",
    "\n",
    "#### Hyperparameters\n",
    "MODEL_TYPE = 'wide_deep'\n",
    "STEPS = 50000  # Number of batches to train\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Wide (linear) model hyperparameters\n",
    "LINEAR_OPTIMIZER = 'adagrad'\n",
    "LINEAR_OPTIMIZER_LR = 0.0621  # Learning rate\n",
    "LINEAR_L1_REG = 0.0           # Regularization rate for FtrlOptimizer\n",
    "LINEAR_L2_REG = 0.0\n",
    "LINEAR_MOMENTUM = 0.0         # Momentum for MomentumOptimizer or RMSPropOptimizer\n",
    "\n",
    "# DNN model hyperparameters\n",
    "DNN_OPTIMIZER = 'adadelta'\n",
    "DNN_OPTIMIZER_LR = 0.1\n",
    "DNN_L1_REG = 0.0           # Regularization rate for FtrlOptimizer\n",
    "DNN_L2_REG = 0.0\n",
    "DNN_MOMENTUM = 0.0         # Momentum for MomentumOptimizer or RMSPropOptimizer\n",
    "\n",
    "# Layer dimensions. Defined as follows to make this notebook runnable from Hyperparameter tuning services like AzureML Hyperdrive\n",
    "DNN_HIDDEN_LAYER_1 = 0     # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_2 = 64    # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_3 = 128   # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_4 = 512   # Note, at least one layer should have nodes.\n",
    "DNN_HIDDEN_UNITS = [h for h in [DNN_HIDDEN_LAYER_1, DNN_HIDDEN_LAYER_2, DNN_HIDDEN_LAYER_3, DNN_HIDDEN_LAYER_4] if h > 0]\n",
    "DNN_USER_DIM = 32          # User embedding feature dimension\n",
    "DNN_ITEM_DIM = 16          # Item embedding feature dimension\n",
    "DNN_DROPOUT = 0.8\n",
    "DNN_BATCH_NORM = 1         # 1 to use batch normalization, 0 if not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Data\n",
    "\n",
    "#### 1.1 Amazon reviews and Amazon meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(DATA_DIR + 'wide_deep_amzn_e_20.csv', header=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>genre</th>\n",
       "      <th>unixTimeStamp</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td>1424217600</td>\n",
       "      <td>Kastar 2-Pack Replacement Battery for Midland ...</td>\n",
       "      <td>$15.99</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td>1422662400</td>\n",
       "      <td>Kastar 2-Pack Replacement Battery for Midland ...</td>\n",
       "      <td>$15.99</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td>1477612800</td>\n",
       "      <td>Kastar 2-Pack Replacement Battery for Midland ...</td>\n",
       "      <td>$15.99</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td>1476316800</td>\n",
       "      <td>Kastar 2-Pack Replacement Battery for Midland ...</td>\n",
       "      <td>$15.99</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td>1474156800</td>\n",
       "      <td>Kastar 2-Pack Replacement Battery for Midland ...</td>\n",
       "      <td>$15.99</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating                         genre  unixTimeStamp  \\\n",
       "0       0       0     5.0  Portable Audio & Accessories     1424217600   \n",
       "1       1       0     5.0  Portable Audio & Accessories     1422662400   \n",
       "2       2       0     5.0  Portable Audio & Accessories     1477612800   \n",
       "3       3       0     5.0  Portable Audio & Accessories     1476316800   \n",
       "4       4       0     5.0  Portable Audio & Accessories     1474156800   \n",
       "\n",
       "                                               title   price  \\\n",
       "0  Kastar 2-Pack Replacement Battery for Midland ...  $15.99   \n",
       "1  Kastar 2-Pack Replacement Battery for Midland ...  $15.99   \n",
       "2  Kastar 2-Pack Replacement Battery for Midland ...  $15.99   \n",
       "3  Kastar 2-Pack Replacement Battery for Midland ...  $15.99   \n",
       "4  Kastar 2-Pack Replacement Battery for Midland ...  $15.99   \n",
       "\n",
       "                       main_cat category  \n",
       "0  Portable Audio & Accessories           \n",
       "1  Portable Audio & Accessories           \n",
       "2  Portable Audio & Accessories           \n",
       "3  Portable Audio & Accessories           \n",
       "4  Portable Audio & Accessories           "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.columns=['userID','itemID', 'rating','genre','unixTimeStamp','title','price','main_cat','category']\n",
    "ratings_df['category'].fillna('', inplace=True)\n",
    "ratings_df['price'].fillna('$$$', inplace=True)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df[['userID','itemID','rating','genre']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Encode Item Features (Genres)\n",
    "To use genres from our model, we multi-hot-encode them with scikit-learn's [MultiLabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html).\n",
    "\n",
    "For example, *Movie id=2355* has three genres, *Animation|Children's|Comedy*, which are being converted into an integer array of the indicator value for each genre like `[0, 0, 1, 1, 1, 0, 0, 0, ...]`. In the later step, we convert this into a float array and feed into the model.\n",
    "\n",
    "> For faster feature encoding, you may load ratings and items separately (by using `movielens.load_item_df`), encode the item-features, then combine the rating and item dataframes by using join-operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres: ['Accessories' 'Accessories & Supplies' 'All Electronics' 'Amazon Devices'\n",
      " 'Apple Products' 'Audio & Video Accessories' 'Automotive'\n",
      " 'Camera & Photo' 'Car & Vehicle Electronics' 'Car Electronics'\n",
      " 'Cell Phones & Accessories' 'Clothing, Shoes & Jewelry'\n",
      " 'Computer Accessories & Peripherals' 'Computer Components' 'Computers'\n",
      " 'Computers & Accessories' 'Controllers' 'Electrical' 'Electronics'\n",
      " 'GPS & Navigation' 'Home & Kitchen' 'Home Audio' 'Home Audio & Theater'\n",
      " 'Industrial & Scientific' 'Laptop Accessories' 'Musical Instruments'\n",
      " 'Office & School Supplies' 'Office Electronics' 'Office Products'\n",
      " 'Portable Audio & Accessories' 'Portable Audio & Video'\n",
      " 'Sports & Fitness' 'Sports & Outdoors' 'Tools & Home Improvement'\n",
      " 'Toys & Games' 'Video Games']\n",
      "Num genres: 36\n"
     ]
    }
   ],
   "source": [
    "# Encode 'genres' into int array (multi-hot representation) to use as item features\n",
    "genres_encoder = sklearn.preprocessing.MultiLabelBinarizer()\n",
    "ratings_df[ITEM_FEAT_COL] = genres_encoder.fit_transform(\n",
    "    ratings_df[ITEM_FEAT_COL].apply(lambda s: s.split(\"|\"))\n",
    ").tolist()\n",
    "\n",
    "print(\"Genres:\", genres_encoder.classes_)\n",
    "print(\"Num genres:\", len(genres_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4209887 train samples and 1403296 test samples\n"
     ]
    }
   ],
   "source": [
    "train, test = python_random_split(ratings_df, ratio=0.75, seed=RANDOM_SEED)\n",
    "\n",
    "print(\"{} train samples and {} test samples\".format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"users_items\"></a>\n",
    "#### Generate users and items datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5613183, 4)\n",
      "(63725, 2)\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# Unique items in the dataset\n",
    "print(ratings_df.shape)\n",
    "items = ratings_df.drop_duplicates(ITEM_COL)[[ITEM_COL, ITEM_FEAT_COL]].reset_index(drop=True)\n",
    "print(items.shape)\n",
    "item_feat_shape = len(items[ITEM_FEAT_COL][0])\n",
    "print(item_feat_shape) # number of genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 63725 items and 830668 users in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Unique users in the dataset\n",
    "users = ratings_df.drop_duplicates(USER_COL)[[USER_COL]].reset_index(drop=True)\n",
    "\n",
    "print(\"Total {} items and {} users in the dataset\".format(len(items), len(users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Jump to Model Serving](#model_serving) if we already have a pre-built model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build Model\n",
    "\n",
    "Wide-and-deep model consists of a linear model and DNN. We use the following hyperparameters and feature sets for the model:\n",
    "\n",
    "<br> | <div align=\"center\">Wide (linear) model</div> | <div align=\"center\">Deep neural networks</div>\n",
    "---|---|---\n",
    "Feature set | <ul><li>User-item co-occurrence features<br>to capture how their co-occurrence<br>correlates with the target rating</li></ul> | <ul><li>Deep, lower-dimensional embedding vectors<br>for every user and item</li><li>Item feature vector</li></ul>\n",
    "Hyperparameters | <ul><li>FTRL optimizer</li><li>Learning rate = 0.0029</li><li>L1 regularization = 0.0</li></ul> | <ul><li>Adagrad optimizer</li><li>Learning rate = 0.1</li><li>Hidden units = [128, 256, 32]</li><li>Dropout rate = 0.4</li><li>Use batch normalization (Batch size = 64)</li><li>User embedding vector size = 4</li><li>Item embedding vector size = 4</li></ul>\n",
    "\n",
    "<br>\n",
    "\n",
    "* [FTRL optimizer](https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf)\n",
    "* [Adagrad optimizer](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n",
    "\n",
    "Note, the hyperparameters are optimized for the training set. We used **Azure Machine Learning service** ([AzureML](https://azure.microsoft.com/en-us/services/machine-learning-service/)) to find the best hyperparameters, where we further split the training set into two subsets for training and validation respectively so that the test set is being separated from the tuning and training phases. For more details, see [azureml_hyperdrive_wide_and_deep.ipynb](../04_model_select_and_optimize/azureml_hyperdrive_wide_and_deep.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS=1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpelq7y_mc\n"
     ]
    }
   ],
   "source": [
    "# Create model checkpoint every n steps. We store the model 5 times.\n",
    "save_checkpoints_steps = max(1, STEPS // 10) # STEPS = 50000\n",
    "TMP_DIR = TemporaryDirectory()\n",
    "model_dir = TMP_DIR.name\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide feature specs:\n",
      "\t VocabularyListCategoricalColumn(key='userID', vocabulary_list=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, ...\n",
      "\t VocabularyListCategoricalColumn(key='itemID', vocabulary_list=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, ...\n",
      "\t CrossedColumn(keys=(VocabularyListCategoricalColumn(key='userID', vocabulary_list=(0, 1, 2, 3, 4, 5, ...\n",
      "Deep feature specs:\n",
      "\t EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='userID', vocabulary_list=(0, ...\n",
      "\t EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='itemID', vocabulary_list=(0, ...\n",
      "\t NumericColumn(key='genre', shape=(36,), default_value=None, dtype=tf.float32, normalizer_fn=None) ...\n"
     ]
    }
   ],
   "source": [
    "# Define wide (linear) and deep (dnn) features\n",
    "wide_columns, deep_columns = wide_deep.build_feature_columns(\n",
    "    users=users[USER_COL].values,\n",
    "    items=items[ITEM_COL].values,\n",
    "    user_col=USER_COL, # userID\n",
    "    item_col=ITEM_COL, # itemID\n",
    "    item_feat_col=ITEM_FEAT_COL, # genre\n",
    "    crossed_feat_dim=1000,\n",
    "    user_dim=DNN_USER_DIM, # 32\n",
    "    item_dim=DNN_ITEM_DIM, # 16\n",
    "    item_feat_shape=item_feat_shape, # 19\n",
    "    model_type=MODEL_TYPE,  # 'wide_deep'\n",
    ")\n",
    "\n",
    "print(\"Wide feature specs:\")\n",
    "for c in wide_columns:\n",
    "    print(\"\\t\", str(c)[:100], \"...\")\n",
    "print(\"Deep feature specs:\")\n",
    "for c in deep_columns:\n",
    "    print(\"\\t\", str(c)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model based on the parameters\n",
    "model = wide_deep.build_model(\n",
    "    model_dir=model_dir,\n",
    "    wide_columns=wide_columns,\n",
    "    deep_columns=deep_columns,\n",
    "    linear_optimizer=tf_utils.build_optimizer(LINEAR_OPTIMIZER, LINEAR_OPTIMIZER_LR, **{\n",
    "        'l1_regularization_strength': LINEAR_L1_REG, # 0.0\n",
    "        'l2_regularization_strength': LINEAR_L2_REG, # 0.0\n",
    "        'momentum': LINEAR_MOMENTUM,  # 0.0\n",
    "    }),\n",
    "    dnn_optimizer=tf_utils.build_optimizer(DNN_OPTIMIZER, DNN_OPTIMIZER_LR, **{\n",
    "        'l1_regularization_strength': DNN_L1_REG, # 0.0\n",
    "        'l2_regularization_strength': DNN_L2_REG, # 0.0\n",
    "        'momentum': DNN_MOMENTUM,  # 0.0\n",
    "    }),\n",
    "    dnn_hidden_units=DNN_HIDDEN_UNITS, # [64, 128, 512]\n",
    "    dnn_dropout=DNN_DROPOUT, # 0.8\n",
    "    dnn_batch_norm=(DNN_BATCH_NORM==1), # DNN_BATCH_NORM = 1\n",
    "    log_every_n_iter=max(1, STEPS//10),  # log 10 times\n",
    "    save_checkpoints_steps=save_checkpoints_steps,\n",
    "    seed=RANDOM_SEED # 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and Evaluate Model\n",
    "\n",
    "Now we are all set to train the model. Here, we show how to utilize session hooks to track model performance while training. Our custom hook `tf_utils.evaluation_log_hook` estimates the model performance on the given data based on the specified evaluation functions. Note we pass test set to evaluate the model on rating metrics while we use <span id=\"ranking-pool\">ranking-pool (all the user-item pairs)</span> for ranking metrics.\n",
    "\n",
    "> Note: The TensorFlow Estimator's default loss calculates Mean Squared Error. Square root of the loss is the same as [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- We cannot prepare ranking evaluation set. The memory requirement is simply too big.\n",
    "- E.g. for 1_000_000 users and 50_000 items, we would need 50 GB of memory\n",
    "- Without the ranking pool, we cannot use ndcg@k or precision@k ranking metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {\n",
    "    'col_user': USER_COL, # \"userID\"\n",
    "    'col_item': ITEM_COL, # \"itemID\"\n",
    "    'col_rating': RATING_COL, # \"rating\"\n",
    "    'col_prediction': PREDICT_COL, # \"prediction\"\n",
    "}\n",
    "ranking_pool = None\n",
    "# Prepare ranking evaluation set, i.e. get the cross join of all user-item pairs\n",
    "# ranking_pool = user_item_pairs(\n",
    "#     user_df=users,\n",
    "#     item_df=items,\n",
    "#     user_col=USER_COL,\n",
    "#     item_col=ITEM_COL,\n",
    "#     user_item_filter_df=train,  # Remove seen items; train: userID, itemID, rating, genre\n",
    "#     shuffle=False,\n",
    "#     seed=RANDOM_SEED\n",
    "# )\n",
    "# ranking_pool has 1682X983 - 75_000 = 1_511_126 cartesian product\n",
    "# 6040 x 3706 - 750156 = 21634084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for metrics in (RANKING_METRICS, RATING_METRICS):\n",
    "#     print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define training hooks to track performance while training\n",
    "# ndcg: Normalized Discounted Cumulative Gain\n",
    "hooks = []\n",
    "if EVALUATE_WHILE_TRAINING: # True\n",
    "    evaluation_logger = tf_utils.MetricsLogger()\n",
    "#     for metrics in (RANKING_METRICS, RATING_METRICS): # ndcg_at_k, precision_at_k; rmse, mae\n",
    "#         if len(metrics) > 0:\n",
    "    hooks.append(\n",
    "        tf_utils.evaluation_log_hook(\n",
    "            model,\n",
    "            logger=evaluation_logger,\n",
    "            true_df=test,\n",
    "            y_col=RATING_COL,\n",
    "#             eval_df=ranking_pool if metrics==RANKING_METRICS else test.drop(RATING_COL, axis=1),\n",
    "            eval_df=test.drop(RATING_COL, axis=1),\n",
    "            every_n_iter=save_checkpoints_steps,\n",
    "            model_dir=model_dir,\n",
    "#                     eval_fns=[evaluator.metrics[m] for m in metrics],\n",
    "            eval_fns=[evaluator.metrics[metrics] for metrics in RATING_METRICS],\n",
    "#             **({**cols, 'k': TOP_K} if metrics==RANKING_METRICS else cols)\n",
    "            **(cols)\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Define training input (sample feeding) function\n",
    "train_fn = tf_utils.pandas_input_fn(\n",
    "    df=train,\n",
    "    y_col=RATING_COL,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=None,  # We use steps=TRAIN_STEPS instead.\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training steps = 1000000, Batch size = 32 (num epochs = 7)\n",
      "WARNING:tensorflow:From /home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow/python/training/adagrad.py:138: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 15:32:25.068376: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-01 15:32:25.803186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 15:32:25.804343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 15:33:11.765537: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-08-01 15:33:16.809980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 15:33:16.810185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 689.2922, step = 0\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 100000...\n",
      "INFO:tensorflow:Saving checkpoints for 100000 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 100000...\n",
      "INFO:tensorflow:global_step/sec: 104.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n",
      "2022-08-01 15:49:13.227980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 15:49:13.228168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 24.614544, step = 100000 (971.602 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 200000...\n",
      "INFO:tensorflow:Saving checkpoints for 200000 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 200000...\n",
      "INFO:tensorflow:global_step/sec: 108.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n",
      "2022-08-01 16:04:35.542443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 16:04:35.542646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 38.00202, step = 200000 (923.090 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 300000...\n",
      "INFO:tensorflow:Saving checkpoints for 300000 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 300000...\n",
      "INFO:tensorflow:global_step/sec: 91.7793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n",
      "2022-08-01 16:22:45.067243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 16:22:45.067446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 44.724503, step = 300000 (1087.890 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 400000...\n",
      "INFO:tensorflow:Saving checkpoints for 400000 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 400000...\n",
      "INFO:tensorflow:global_step/sec: 115.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n",
      "2022-08-01 16:37:12.703774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 16:37:12.703974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 58.78936, step = 400000 (866.390 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 500000...\n",
      "INFO:tensorflow:Saving checkpoints for 500000 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "WARNING:tensorflow:From /home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow/python/training/saver.py:1052: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 500000...\n",
      "INFO:tensorflow:global_step/sec: 90.8427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n",
      "2022-08-01 16:55:33.376569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 16:55:33.376775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 20.139492, step = 500000 (1103.844 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 600000...\n",
      "INFO:tensorflow:Saving checkpoints for 600000 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 600000...\n",
      "INFO:tensorflow:global_step/sec: 91.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n",
      "2022-08-01 17:13:43.887768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 17:13:43.887969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 27.898827, step = 600000 (1089.256 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 700000...\n",
      "INFO:tensorflow:Saving checkpoints for 700000 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 700000...\n",
      "INFO:tensorflow:global_step/sec: 91.3655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n",
      "2022-08-01 17:31:58.825113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 17:31:58.825296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 28.18411, step = 700000 (1095.600 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 800000...\n",
      "INFO:tensorflow:Saving checkpoints for 800000 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 800000...\n",
      "INFO:tensorflow:global_step/sec: 98.5087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n",
      "2022-08-01 17:48:53.846314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 17:48:53.846524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 27.919865, step = 800000 (1012.857 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 900000...\n",
      "INFO:tensorflow:Saving checkpoints for 900000 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 900000...\n",
      "INFO:tensorflow:global_step/sec: 105.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n",
      "2022-08-01 18:04:37.905820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 18:04:37.906021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 16.981068, step = 900000 (938.420 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000000...\n",
      "INFO:tensorflow:Saving checkpoints for 1000000 into /tmp/tmpelq7y_mc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000000...\n",
      "INFO:tensorflow:Loss for final step: 25.884441.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Training steps = {}, Batch size = {} (num epochs = {})\"\n",
    "    .format(STEPS, BATCH_SIZE, (STEPS*BATCH_SIZE)//len(train))\n",
    ")\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "try:\n",
    "    model.train(\n",
    "        input_fn=train_fn,\n",
    "        hooks=hooks,\n",
    "        steps=STEPS\n",
    "    )\n",
    "except tf.compat.v1.train.NanLossDuringTrainingError:\n",
    "    import warnings\n",
    "    warnings.warn(\n",
    "        \"Training stopped with NanLossDuringTrainingError. \"\n",
    "        \"Try other optimizers, smaller batch size and/or smaller learning rate.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': [4.560691371843296,\n",
       "  1.097325716796562,\n",
       "  1.0777041280600417,\n",
       "  1.0702420787639841,\n",
       "  1.0652975836798118,\n",
       "  1.063317462395253,\n",
       "  1.060942881146609,\n",
       "  1.059553989867443,\n",
       "  1.0584321014068874,\n",
       "  1.057801120217181],\n",
       " 'mae': [4.414920451895229,\n",
       "  0.8618665845426546,\n",
       "  0.8118637643674194,\n",
       "  0.7971600603018356,\n",
       "  0.7828303697282187,\n",
       "  0.7874117839124775,\n",
       "  0.7746461160293763,\n",
       "  0.7682480634140209,\n",
       "  0.7663158783404408,\n",
       "  0.7638086217996314]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = evaluation_logger.get_log()\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": [
        4.560691371843296,
        1.097325716796562,
        1.0777041280600417,
        1.0702420787639841,
        1.0652975836798118,
        1.063317462395253,
        1.060942881146609,
        1.059553989867443,
        1.0584321014068874,
        1.057801120217181
       ],
       "encoder": "json",
       "name": "eval_rmse",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "eval_rmse"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": [
        4.414920451895229,
        0.8618665845426546,
        0.8118637643674194,
        0.7971600603018356,
        0.7828303697282187,
        0.7874117839124775,
        0.7746461160293763,
        0.7682480634140209,
        0.7663158783404408,
        0.7638086217996314
       ],
       "encoder": "json",
       "name": "eval_mae",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "eval_mae"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scrapbook as sb\n",
    "if EVALUATE_WHILE_TRAINING:\n",
    "    logs = evaluation_logger.get_log()\n",
    "    for i, (m, v) in enumerate(logs.items(), 1):\n",
    "        sb.glue(\"eval_{}\".format(m), v)\n",
    "        x = [save_checkpoints_steps*i for i in range(1, len(v)+1)]\n",
    "        plot.line_graph(\n",
    "            values=list(zip(v, x)),\n",
    "            labels=m,\n",
    "            x_name=\"steps\",\n",
    "            y_name=m,\n",
    "            subplot=(math.ceil(len(logs)/2), 2, i),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 TensorBoard\n",
    "\n",
    "Once the train is done, you can browse the details of the training results as well as the metrics we logged from [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard).\n",
    "\n",
    "[]()|[]()|[]()\n",
    ":---:|:---:|:---:\n",
    "<img src=\"https://recodatasets.z20.web.core.windows.net/images/tensorboard_0.png?sanitize=true\"> |  <img src=\"https://recodatasets.z20.web.core.windows.net/images/tensorboard_1.png?sanitize=true\"> | <img src=\"https://recodatasets.z20.web.core.windows.net/images/tensorboard_2.png?sanitize=true\">\n",
    "\n",
    "To open the TensorBoard, open a terminal from the same directory of this notebook, run `tensorboard --logdir=model_checkpoints`, and open http://localhost:6006 from a browser.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test and Export Model\n",
    "\n",
    "#### 4.1 Item rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpelq7y_mc/model.ckpt-1000000\n",
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 18:23:04.436751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 18:23:04.436942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 1.0574871868401199,
       "encoder": "json",
       "name": "rmse",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "rmse"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.7618798790135353,
       "encoder": "json",
       "name": "mae",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "mae"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 1.0574871868401199, 'mae': 0.7618798790135353}\n"
     ]
    }
   ],
   "source": [
    "if len(RATING_METRICS) > 0:\n",
    "    predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=test)))\n",
    "    prediction_df = test.drop(RATING_COL, axis=1)\n",
    "    prediction_df[PREDICT_COL] = [p['predictions'][0] for p in predictions]\n",
    "    \n",
    "    rating_results = {}\n",
    "    for m in RATING_METRICS:\n",
    "        result = evaluator.metrics[m](test, prediction_df, **cols)\n",
    "        sb.glue(m, result)\n",
    "        rating_results[m] = result\n",
    "    print(rating_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Recommend k items\n",
    "For top-k recommendation evaluation, we use the ranking pool (all the user-item pairs) we prepared at the [training step](#ranking-pool). \n",
    "\n",
    "The difference is we remove users' seen items from the pool in this step which is more natural to the movie recommendation scenario.\n",
    "\n",
    "### Notes:\n",
    "- We cannot run this step as we do not have a ranking pool.\n",
    "- Jump to the [model serving step](#model_serving) to calculate ranking metric when we cannot build a ranking pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_pool = None\n",
    "\n",
    "if ranking_pool is not None and len(RANKING_METRICS) > 0:\n",
    "    predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=ranking_pool)))\n",
    "    prediction_df = ranking_pool.copy()\n",
    "    prediction_df[PREDICT_COL] = [p['predictions'][0] for p in predictions]\n",
    "\n",
    "    ranking_results = {}\n",
    "    for m in RANKING_METRICS:\n",
    "        result = evaluator.metrics[m](test, prediction_df, **{**cols, 'k': TOP_K}) # TOP_K = 10\n",
    "        sb.glue(m, result)\n",
    "        ranking_results[m] = result\n",
    "    print(ranking_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Export Model\n",
    "Finally, we export the model so that we can load later for re-training, evaluation, and prediction.\n",
    "Examples of how to load, re-train, and evaluate the saved model can be found from [azureml_hyperdrive_wide_and_deep.ipynb](../04_model_select_and_optimize/azureml_hyperdrive_wide_and_deep.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(EXPORT_DIR_BASE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiv/anaconda3/envs/RecSys_39/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\n",
      "2022-08-01 18:25:26.877366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 18:25:26.877560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n",
      "2022-08-01 18:25:29.761346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 18:25:29.761591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n",
      "2022-08-01 18:25:32.300040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 18:25:32.300224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "application/scrapbook.scrap.text+json": {
       "data": "./outputs/model/1659403524",
       "encoder": "text",
       "name": "saved_model_dir",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "saved_model_dir"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to ./outputs/model/1659403524\n"
     ]
    }
   ],
   "source": [
    "exported_path = tf_utils.export_model(\n",
    "    model=model,\n",
    "    train_input_fn=train_fn,\n",
    "    eval_input_fn=tf_utils.pandas_input_fn(\n",
    "        df=test, y_col=RATING_COL\n",
    "    ),\n",
    "    tf_feat_cols=wide_columns+deep_columns,\n",
    "    base_dir=EXPORT_DIR_BASE\n",
    ")\n",
    "sb.glue('saved_model_dir', str(exported_path))\n",
    "print(\"Model exported to\", str(exported_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the event file so that the model folder can be cleaned up.\n",
    "summary_writer = tf.compat.v1.summary.FileWriterCache.get(model.model_dir)\n",
    "summary_writer.close()\n",
    "\n",
    "# Cleanup temporary directory if used\n",
    "if TMP_DIR is not None:\n",
    "    TMP_DIR.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model_serving\"></a>\n",
    "# Model Serving\n",
    "\n",
    "- If running test set's rating, must restart the kernel and disable GPU\n",
    "- If running ranking, then no need to restart, but a restart does no harm.\n",
    "- Run the notebook till the generation of [users, items dataframes](#users_items) and jump to this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {\n",
    "    'col_user': USER_COL,\n",
    "    'col_item': ITEM_COL,\n",
    "    'col_rating': RATING_COL,\n",
    "    'col_prediction': 'prediction'\n",
    "}\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 18:39:44.550481: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-01 18:39:45.021353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5672 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-01 18:39:45.021882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6114 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = './outputs/model/1659403524'\n",
    "\n",
    "saved_model = tf.saved_model.load(MODEL_DIR, tags=\"serve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating metrics (rmse, mae) on test set (won't run on GPU)\n",
    "\n",
    "- Must run on CPU as it will try to create a 3.5Mx512 byte array on GPU running out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make sure you run this cell on CPU\n",
    "X_test = test.drop(RATING_COL, axis=1)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rating prediction\n",
    "predictions = saved_model.signatures[\"predict\"](\n",
    "        examples=tf_utils.pandas_input_fn_for_saved_model(\n",
    "            df=X_test,\n",
    "            feat_name_type={\n",
    "                USER_COL: int,\n",
    "                ITEM_COL: int,\n",
    "                ITEM_FEAT_COL: list\n",
    "            }\n",
    "        )()[\"inputs\"]\n",
    "    )\n",
    "\n",
    "prediction_df = X_test.copy()\n",
    "# prediction_df['prediction'] = [p['outputs'][0] for p in predictions]\n",
    "prediction_df['prediction'] = predictions['predictions'].numpy()\n",
    "print(prediction_df['prediction'].describe(), \"\\n\")\n",
    "for m in RATING_METRICS:\n",
    "    result = evaluator.metrics[m](test, prediction_df, **cols)\n",
    "    print(m, \"=\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking metrics (ndcg@k, precision@k)\n",
    "\n",
    "- Can run on GPU  but it is slow (proportional to the number of users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k_one_user(rating_true, rating_pred,\n",
    "                       col_user=USER_COL, col_item=ITEM_COL, col_rating=RATING_COL,\n",
    "                       col_prediction=PREDICT_COL, relevancy_method=\"top_k\", k=DEFAULT_K,\n",
    "                       threshold=DEFAULT_THRESHOLD):\n",
    "    df_hit, df_hit_count, n_users = evaluator.merge_ranking_true_pred(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "    assert(n_users==1)\n",
    "    return df_hit, df_hit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must ignore items already seen (makes sense for movies but Amazon products???)\n",
    "all_items_set = set(items[ITEM_COL].values)\n",
    "\n",
    "# no point of running ranking if a userID is not present in test\n",
    "all_users_test = set(test[USER_COL].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 646/830668 [00:01<25:47, 536.24it/s]2022-08-01 18:45:24.373170: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 830668/830668 [24:21<00:00, 568.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df_hit_master = pd.DataFrame(columns=[USER_COL, ITEM_COL, \"rank\"])\n",
    "df_hit_count_master = pd.DataFrame(columns=[USER_COL, \"hit\", \"actual\"])\n",
    "\n",
    "num_users = 0\n",
    "k = 10000 # something big to test without training the model for a very long time!\n",
    "\n",
    "for user in (pbar := tqdm(users[USER_COL])): # requires Python 3.8 walrus operator\n",
    "    if user not in all_users_test:\n",
    "        continue\n",
    "    # print(user)\n",
    "    \n",
    "    tmp_df = train[train[USER_COL]==user]  # remove seen items\n",
    "    items_rated = tmp_df[ITEM_COL].values\n",
    "    items_rated_set = set(items_rated)\n",
    "    if len(items_rated_set) < 100: # only include users who have rated at least 100 items\n",
    "        continue\n",
    "    \n",
    "    items_not_seen = all_items_set - items_rated_set\n",
    "    lst_items_not_seen = list(items_not_seen)\n",
    "    \n",
    "    len_lst = len(lst_items_not_seen)\n",
    "    tmp_df = items[items[ITEM_COL].isin(lst_items_not_seen)]\n",
    "    test_dict = {USER_COL:[user]*len_lst,\n",
    "                 ITEM_COL:lst_items_not_seen,\n",
    "                 ITEM_FEAT_COL:tmp_df[ITEM_FEAT_COL].values}\n",
    "    # print(len(items_rated_set), len(items_not_seen))\n",
    "\n",
    "    X_test = pd.DataFrame(test_dict)\n",
    "    # Rating prediction\n",
    "    predictions = saved_model.signatures[\"predict\"](\n",
    "            examples=tf_utils.pandas_input_fn_for_saved_model(\n",
    "                df=X_test,\n",
    "                feat_name_type={\n",
    "                    USER_COL: int,\n",
    "                    ITEM_COL: int,\n",
    "                    ITEM_FEAT_COL: list\n",
    "                }\n",
    "            )()[\"inputs\"]\n",
    "        )\n",
    "\n",
    "    prediction_df = X_test.copy()\n",
    "    # prediction_df['prediction'] = [p['outputs'][0] for p in predictions]\n",
    "    prediction_df['prediction'] = predictions['predictions'].numpy()\n",
    "    \n",
    "    df_hit_user, df_hit_count_user = ndcg_at_k_one_user(test, prediction_df, k=k)\n",
    "    df_hit_master = pd.concat([df_hit_master, df_hit_user])\n",
    "    df_hit_count_master = pd.concat([df_hit_count_master, df_hit_count_user])\n",
    "    \n",
    "    num_users += 1\n",
    "    pbar.set_description(f'#users {num_users}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ndcg@k, precision@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0719124581920513"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = num_users\n",
    "\n",
    "# calculate discounted gain for hit items\n",
    "df_dcg = df_hit_master.copy()\n",
    "# relevance in this case is always 1\n",
    "df_dcg[\"dcg\"] = 1 / np.log1p(df_dcg[\"rank\"].astype('float32'))\n",
    "# sum up discount gained to get discount cumulative gain\n",
    "df_dcg = df_dcg.groupby(USER_COL, as_index=False, sort=False).agg({\"dcg\": \"sum\"})\n",
    "\n",
    "# calculate ideal discounted cumulative gain\n",
    "df_ndcg = pd.merge(df_dcg, df_hit_count_master, on=[USER_COL])\n",
    "df_ndcg[\"idcg\"] = df_ndcg[\"actual\"].apply(\n",
    "    lambda x: sum(1 / np.log1p(range(1, min(x, k) + 1)))\n",
    ")\n",
    "\n",
    "# DCG over IDCG is the normalized DCG\n",
    "(df_ndcg[\"dcg\"] / df_ndcg[\"idcg\"]).sum() / n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009674418604651162"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision @ k\n",
    "(df_hit_count_master[\"hit\"] / k).sum() / n_users"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a9a0c422ff9f08d62211b9648017c63b0a26d2c935edc37ebb8453675d13bb5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
